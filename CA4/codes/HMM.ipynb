{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams , ConditionalFreqDist\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(fileName,sheet):\n",
    "    xl_file = pd.read_excel(fileName,sheet, header=None)\n",
    "    df = pd.DataFrame(xl_file)\n",
    "    df = df.fillna(method='ffill')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = readFile('viterbi_train.xlsx','Sheet1')\n",
    "dftest = readFile('viterbi_test.xlsx','Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if create it call loadSentenceAndTags function \n",
    "def createSentenceAndTags(df,sentfirst,sentlast):\n",
    "    sentences = []\n",
    "    sentence_tags = []\n",
    "    for i in range(sentfirst,sentlast):\n",
    "        sent = df[df[0]== ('Sentence: '+str(i))]\n",
    "        sentences.append(sent[1])\n",
    "        sentence_tags.append(sent[2])\n",
    "    with open('sentences2.data', 'wb') as filehandle:\n",
    "        # store the data as binary data stream\n",
    "        pickle.dump(sentences, filehandle)\n",
    "    with open('sentence_tags2.data', 'wb') as filehandle:\n",
    "        # store the data as binary data stream\n",
    "        pickle.dump(sentence_tags, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSentenceAndTags():\n",
    "    with open('sentences2.data', 'rb') as filehandle:\n",
    "        # read the data as binary data stream\n",
    "        sentences = pickle.load(filehandle)\n",
    "    with open('sentence_tags2.data', 'rb') as filehandle:\n",
    "        # read the data as binary data stream\n",
    "        sentence_tags = pickle.load(filehandle)\n",
    "    return sentences,sentence_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "createSentenceAndTags(df,30000,34000)\n",
    "sentences,sentence_tags = loadSentenceAndTags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "createSentenceAndTags(dftest,34000,35001)\n",
    "testSentences,testSentence_tags = loadSentenceAndTags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set([])\n",
    "for s in sentences:\n",
    "    for w in s:\n",
    "        vocab.add(str(w).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_file = pd.read_excel('pos_list.xlsx')\n",
    "tagf = pd.DataFrame(xl_file, columns= ['POS_list'])\n",
    "vocabtags = set(tagf['POS_list'])\n",
    "vocabtags.add('-#start#-')\n",
    "vocabtags.add('-#end#-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSentTagPair(sentences,sentence_tags):\n",
    "    sentenceTag = []\n",
    "    sent = []\n",
    "    x = 0\n",
    "    for i in range(len(sentences)):\n",
    "        sent = []\n",
    "        sent.append(('-#start#-','-#start#-'))\n",
    "        for j in range(x,x+len(sentences[i])):\n",
    "            x += 1\n",
    "            sent.append((sentences[i][j],sentence_tags[i][j]))\n",
    "        sent.append(('-#end#-','-#end#-'))\n",
    "        sentenceTag.append(sent)\n",
    "    return sentenceTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = createSentTagPair(sentences,sentence_tags)\n",
    "test_data = createSentTagPair(testSentences,testSentence_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWords=[]\n",
    "testTags=[]\n",
    "for sent in test_data:\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for (word,tag) in sent:\n",
    "        x.append(str(word).lower())\n",
    "        y.append(tag)\n",
    "    testWords.append(x)\n",
    "    testTags.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEmissionProb():\n",
    "    tagWords = {}\n",
    "    emissionProb = {}\n",
    "    for sent in train_data:\n",
    "        for (word,tag) in sent:\n",
    "            word = str(word).lower()\n",
    "            if tag in tagWords:\n",
    "                if word in tagWords[tag] :\n",
    "                    tagWords[tag][word] += 1\n",
    "                else:\n",
    "                    tagWords[tag][word] = 1\n",
    "            else:\n",
    "                tagWords[tag] = {word:1}\n",
    "    for tag in tagWords.keys():\n",
    "        emissionProb[tag] = {}\n",
    "        for word in tagWords[tag].keys():\n",
    "            emissionProb[tag][word] = tagWords[tag][word] / sum(tagWords[tag].values())\n",
    "    return emissionProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissionProb = createEmissionProb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTransitionProb():\n",
    "    \n",
    "    tags = []\n",
    "    for sent in train_data:\n",
    "        for (word,tag) in sent:\n",
    "            tags.append(tag)\n",
    "    brown_trigrams = bigrams(tags)\n",
    "    condition_pairs = ((w0,w1) for w0, w1 in brown_trigrams)\n",
    "    cfd_brown = ConditionalFreqDist(condition_pairs)\n",
    "    transitionProb={}\n",
    "    print(cfd_brown.keys())\n",
    "    for tag1 in cfd_brown.keys():\n",
    "#         if(tag1 != '-#end#-'):\n",
    "        transitionProb[tag1] = {}\n",
    "        for tag2 in cfd_brown[tag1].keys():\n",
    "            transitionProb[tag1][tag2]=cfd_brown[tag1][tag2]/sum(cfd_brown[tag1].values())\n",
    "    return transitionProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['-#start#-', 'JJ', 'NNP', 'VBZ', 'VBN', 'TO', 'VB', 'DT', 'NN', '.', '-#end#-', ',', 'CC', 'POS', 'VBP', 'VBG', 'IN', 'NNS', 'PRP', 'RP', 'VBD', 'MD', 'JJR', 'RB', 'EX', '$', 'CD', 'RBR', 'PRP$', 'JJS', 'WP', 'WRB', 'WDT', 'PDT', '``', 'NNPS', 'RBS', 'WP$', 'LRB', 'RRB', ':', ';'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['-#start#-', 'JJ', 'NNP', 'VBZ', 'VBN', 'TO', 'VB', 'DT', 'NN', '.', '-#end#-', ',', 'CC', 'POS', 'VBP', 'VBG', 'IN', 'NNS', 'PRP', 'RP', 'VBD', 'MD', 'JJR', 'RB', 'EX', '$', 'CD', 'RBR', 'PRP$', 'JJS', 'WP', 'WRB', 'WDT', 'PDT', '``', 'NNPS', 'RBS', 'WP$', 'LRB', 'RRB', ':', ';'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitionProb = createTransitionProb()\n",
    "transitionProb.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi():\n",
    "    predictedTags = []                \n",
    "    for i in range(int(len(testWords))):\n",
    "        sent = testWords[i]\n",
    "        viterbiMatrix = {}              \n",
    "        for j in range(len(sent)):\n",
    "            word = sent[j]\n",
    "            #first word in sentence\n",
    "            if j == 1:                \n",
    "                viterbiMatrix[j] = {}\n",
    "                for tag in transitionProb.keys():\n",
    "                    if word in vocab and word in emissionProb[tag].keys() and tag in transitionProb['-#start#-']:\n",
    "                        viterbiMatrix[j][tag] = ['-#start#-',transitionProb['-#start#-'][tag]*emissionProb[tag][word]]\n",
    "                    else:\n",
    "                        viterbiMatrix[j][tag] = ['-#start#-',0.00000001]\n",
    "\n",
    "            # for all words of sentence except first\n",
    "            if(j > 1):\n",
    "                viterbiMatrix[j] = {}\n",
    "                previous_states = list(viterbiMatrix[j-1].keys())\n",
    "                for tag in transitionProb.keys(): \n",
    "                    if(tag != '-#start#-'):\n",
    "                        tempValus = []\n",
    "                        for ptag in previous_states:                         \n",
    "                            if word in vocab and word in emissionProb[tag].keys() and tag in transitionProb[ptag] :\n",
    "                                tempValus.append(viterbiMatrix[j-1][ptag][1]*transitionProb[ptag][tag]*emissionProb[tag][word])\n",
    "                            else:\n",
    "                                tempValus.append(viterbiMatrix[j-1][ptag][1]*0.00000001)\n",
    "                        index = tempValus.index(max(tempValus))\n",
    "                        bestpt = previous_states[index]\n",
    "                        viterbiMatrix[j][tag]=[bestpt,max(tempValus)]\n",
    "        pred_tags = []\n",
    "        total_steps_num = viterbiMatrix.keys()\n",
    "        lensent = len(sent) - 1\n",
    "        for w in range(lensent):\n",
    "            i = lensent - w\n",
    "            if i == lensent:\n",
    "                pred_tags.append('-#end#-')\n",
    "                pred_tags.append(viterbiMatrix[i]['-#end#-'][0])\n",
    "            if i<lensent and i>0:\n",
    "                pred_tags.append(viterbiMatrix[i][pred_tags[len(pred_tags)-1]][0])\n",
    "        predictedTags.append(list(reversed(pred_tags)))\n",
    "    return predictedTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedTags = viterbi() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for i in range(len(predictedTags)):\n",
    "    pred.append(predictedTags[i][1:len(predictedTags[i])-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(len(pred)):\n",
    "    for j in range(len(pred[i])):\n",
    "        result.append(pred[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest['predict'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('outputHMM.xlsx')\n",
    "# write dataframe to excel\n",
    "dftest.to_excel(writer)\n",
    "# save the excel\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.8871004001618632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy = ',accuracy_score(dftest[2],result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.9274104498228184\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print('Precision = ',precision_score(dftest[2],result,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall =  0.8871004001618632\n"
     ]
    }
   ],
   "source": [
    "print('recall = ',recall_score(dftest[2],result,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
