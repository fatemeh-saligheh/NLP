{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from random import shuffle \n",
    "import string\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import FreqDist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_reviews.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for category in movie_reviews.categories():\n",
    "    for fileid in movie_reviews.fileids(category):\n",
    "        reviews.append((movie_reviews.words(fileid), category))\n",
    "shuffle(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [word for word in movie_reviews.words()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(allWords):\n",
    "    # preprocess\n",
    "    #remove stop words\n",
    "    stopword = stopwords.words('english')\n",
    "    all_words_without_stopwords = [word.lower() for word in allWords if word not in stopword]\n",
    "    \n",
    "    # preprocess\n",
    "    #remove punctuation\n",
    "    punctuations = '''!()-[]--'{}ØŒ;:'\"\\,<>./?@#$%^&*_~'''\n",
    "    all_words_without_punctuation1 = [word for word in all_words_without_stopwords if word not in string.punctuation]\n",
    "    all_words_without_punctuation = [word for word in all_words_without_punctuation1 if word not in punctuations]\n",
    "    \n",
    "    # preprocess\n",
    "    #remove numbers\n",
    "    all_words_without_numbers = []\n",
    "    for word in all_words_without_punctuation:\n",
    "        x = re.sub(r\"\\d+\", \"\", word)\n",
    "        if(x != ''):\n",
    "            all_words_without_numbers.append(x)\n",
    "            \n",
    "    # preprocess\n",
    "    #lemmatization\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    all_words_lemmatized = [lemmatizer.lemmatize(word) for word in all_words_without_numbers]\n",
    "    \n",
    "    return all_words_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = preprocess(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_frequency = FreqDist(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34705"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('brite', 1)\n",
      "('bonet', 1)\n",
      "('overlong', 22)\n",
      "('spectacle', 30)\n",
      "('marry', 62)\n",
      "('super', 74)\n",
      "('witty', 97)\n"
     ]
    }
   ],
   "source": [
    "print(all_words_frequency.most_common(len(all_words_frequency))[len(all_words_frequency)-10000])\n",
    "print(all_words_frequency.most_common(len(all_words_frequency))[len(all_words_frequency)-2000])\n",
    "print(all_words_frequency.most_common(len(all_words_frequency))[len(all_words_frequency)-30000])\n",
    "print(all_words_frequency.most_common(len(all_words_frequency))[len(all_words_frequency)-31000])\n",
    "print(all_words_frequency.most_common(len(all_words_frequency))[len(all_words_frequency)-32000])\n",
    "print(all_words_frequency.most_common(len(all_words_frequency))[len(all_words_frequency)-33000])\n",
    "print(all_words_frequency.most_common(len(all_words_frequency))[len(all_words_frequency)-33400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = all_words_frequency.most_common(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "negWords = []\n",
    "posWords = []\n",
    "for review,category in reviews:\n",
    "    if(category == 'neg'):\n",
    "        for word in review:\n",
    "            negWords.append(word)\n",
    "    if(category == 'pos'):\n",
    "        for word in review:\n",
    "            posWords.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "preNegWords = preprocess(negWords)\n",
    "prePosWords = preprocess(posWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "negFreq = FreqDist(preNegWords)\n",
    "negFreqDist = negFreq.most_common(len(negFreq))\n",
    "posFreq = FreqDist(prePosWords)\n",
    "posFreqDist = posFreq.most_common(len(posFreq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "negFeatureDist = []\n",
    "posFeatureDist = []\n",
    "for feature,featfreq in features:\n",
    "    for word,freq in negFreqDist:\n",
    "        if feature == word:\n",
    "            negFeatureDist.append((word,freq/featfreq))\n",
    "    for word,freq in posFreqDist:\n",
    "        if feature == word:\n",
    "            posFeatureDist.append((word,freq/featfreq))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayes(review):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
